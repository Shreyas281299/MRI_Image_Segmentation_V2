{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MRI Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import models,datasets,layers\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import imutils\n",
    "import os\n",
    "from os import listdir\n",
    "import SimpleITK\n",
    "from imutils import paths\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from skimage.morphology import extrema\n",
    "from skimage.morphology import watershed as skwater\n",
    "##image = cv.imread(directory + \"\\ \" + filename)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_brain_contour(img):\n",
    "    def ShowImage(title,img):\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.axis('Off')\n",
    "        plt.imshow(img,cmap='gray')\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "    \n",
    "\n",
    "    org_img = img\n",
    "    gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv.threshold(gray,0,255,cv.THRESH_OTSU)\n",
    "    ret, markers = cv.connectedComponents(thresh)\n",
    "    #Get the area taken by each component. Ignore label 0 since this is the background.\n",
    "    marker_area = [np.sum(markers==m) for m in range(np.max(markers)) if m!=0] \n",
    "    #Get label of largest component by area\n",
    "    largest_component = np.argmax(marker_area)+1 #Add 1 since we dropped zero above                        \n",
    "    #Get pixels which correspond to the brain\n",
    "    brain_mask = markers==largest_component\n",
    "\n",
    "    img = org_img\n",
    "    brain_out = img.copy()\n",
    "    #In a copy of the original image, clear those pixels that don't correspond to the brain\n",
    "    brain_out[brain_mask==False] = (0,0,0)\n",
    "\n",
    "    img = org_img\n",
    "    gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv.threshold(gray,0,255,cv.THRESH_BINARY_INV+cv.THRESH_OTSU)\n",
    "\n",
    "\n",
    "    # noise removal\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    opening = cv.morphologyEx(thresh,cv.MORPH_OPEN,kernel, iterations = 2)\n",
    "\n",
    "    # sure background area\n",
    "    sure_bg = cv.dilate(opening,kernel,iterations=3)\n",
    "\n",
    "    # Finding sure foreground area\n",
    "    dist_transform = cv.distanceTransform(opening,cv.DIST_L2,5)\n",
    "    ret, sure_fg = cv.threshold(dist_transform,0.7*dist_transform.max(),255,0)\n",
    "\n",
    "    # Finding unknown region\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "    unknown = cv.subtract(sure_bg,sure_fg)\n",
    "\n",
    "    # Marker labelling\n",
    "    ret, markers = cv.connectedComponents(sure_fg)\n",
    "\n",
    "    # Add one to all labels so that sure background is not 0, but 1\n",
    "    markers = markers+1\n",
    "\n",
    "\n",
    "    # Now, mark the region of unknown with zero\n",
    "    markers[unknown==255] = 0\n",
    "    markers = cv.watershed(img,markers)\n",
    "    img[markers == -1] = [255,0,0]\n",
    "\n",
    "    im1 = cv.cvtColor(img,cv.COLOR_HSV2RGB)\n",
    "    \n",
    "    \n",
    "    blur1 = cv.bilateralFilter(gray,9,75,75)\n",
    "    #gaussian filter\n",
    "    blur2 = cv.GaussianBlur(gray,(5,5),0)\n",
    "    # Threshold the image, then perform a series of erosions +\n",
    "    # dilations to remove any small regions of noise\n",
    "    thresh = cv.erode(thresh, None, iterations=2)\n",
    "\n",
    "\n",
    "    # Find contours in thresholded image, then grab the largest one\n",
    "    cnts = cv.findContours(thresh.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    c = max(cnts, key=cv.contourArea)\n",
    "    \n",
    "    # Find the extreme points\n",
    "    extLeft = tuple(c[c[:, :, 0].argmin()][0])\n",
    "    extRight = tuple(c[c[:, :, 0].argmax()][0])\n",
    "    extTop = tuple(c[c[:, :, 1].argmin()][0])\n",
    "    extBot = tuple(c[c[:, :, 1].argmax()][0])\n",
    "\n",
    "    # crop new image out of the original image using the four extreme points (left, right, top, bottom)\n",
    "    new_image = im1[extTop[1]:extBot[1], extLeft[0]:extRight[0]]  \n",
    "    #### ShowImage('Water_shed_cropped image',new_image) ####\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]     ## Images    \n",
    "Y=[]     ## Labels \n",
    "images_yes = list(paths.list_images('/Users/apple/Desktop/Image processing/archive/yes'))\n",
    "for i in images_yes:\n",
    "    # load the image\n",
    "        image = cv.imread(i)\n",
    "        # crop the brain and ignore the unnecessary rest part of the image\n",
    "        image = crop_brain_contour(image)\n",
    "        # resize image\n",
    "        image = cv.resize(image, dsize=(240, 240), interpolation=cv.INTER_CUBIC)\n",
    "        # normalize values\n",
    "        image = image / 255.\n",
    "        # convert image to numpy array and append it to X\n",
    "        X.append(image)\n",
    "        Y.append(1)\n",
    "        ########## We have here X --> images of tumour vala brain Y--> all 1's\n",
    "images_no = list(paths.list_images('/Users/apple/Desktop/Image processing/archive/no'))\n",
    "for i in images_no:\n",
    "    # load the image\n",
    "        image = cv.imread(i)\n",
    "        # crop the brain and ignore the unnecessary rest part of the image\n",
    "        image = crop_brain_contour(image)\n",
    "        # resize image\n",
    "        image = cv.resize(image, dsize=(240, 240), interpolation=cv.INTER_CUBIC)\n",
    "        # normalize values\n",
    "        image = image / 255.\n",
    "        # convert image to numpy array and append it to X\n",
    "        X.append(image)\n",
    "        Y.append(0)\n",
    "X = np.array(X)\n",
    "## def func(X):\n",
    " #   for each element in X:\n",
    " #       X_segment.append(Segemennted (x))\n",
    "        \n",
    "Y = np.array(Y)\n",
    "# Shuffle the data\n",
    "X, Y = shuffle(X, Y)    \n",
    "## printing an image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomly Splitting the data into test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169, 240, 240, 3)\n",
      "(169,)\n"
     ]
    }
   ],
   "source": [
    "## Data loading\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "## Data normalising\n",
    "X_train,X_test = X_train/255,X_test/255\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Neural Network \n",
    "model = models.Sequential()\n",
    "## 1st Layer is convolutional layer with relu activation function\n",
    "model.add(layers.Conv2D(32,(3,3),activation ='relu',input_shape=(240,240,3)))\n",
    "## 2nd Layer is Maxpooling layer for the convolutional layer\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "## 3rd and 4th layer are same as above. 4th layer has 32 units\n",
    "model.add(layers.Conv2D(64,(3,3),activation = 'relu' ))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "## 5th layer is another convolutional layer with 32 units\n",
    "model.add(layers.Conv2D(64,(3,3),activation = 'relu' ))\n",
    "##6th layer is Flattening layee\n",
    "model.add(layers.Flatten())\n",
    "##7th layer is a dense layer with 64 units with relu activation function\n",
    "model.add(layers.Dense(units= 64,activation='relu'))\n",
    "##7th layer is a dense layer with 64 units with relu activation function\n",
    "model.add(layers.Dense(units= 32,activation='relu'))\n",
    "## 8th and the final layer is another dense layer with softmax function with 2 units\n",
    "model.add(layers.Dense(units= 2,activation='sigmoid'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 [==============================] - 17s 3s/step - loss: 0.6679 - accuracy: 0.5858 - val_loss: 0.6855 - val_accuracy: 0.5714\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 15s 3s/step - loss: 0.6667 - accuracy: 0.6331 - val_loss: 0.6827 - val_accuracy: 0.5714\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 13s 2s/step - loss: 0.6619 - accuracy: 0.6331 - val_loss: 0.7005 - val_accuracy: 0.5714\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 13s 2s/step - loss: 0.6623 - accuracy: 0.6331 - val_loss: 0.6917 - val_accuracy: 0.5714\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 17s 3s/step - loss: 0.6591 - accuracy: 0.6331 - val_loss: 0.6888 - val_accuracy: 0.5714\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 24s 4s/step - loss: 0.6566 - accuracy: 0.6331 - val_loss: 0.6849 - val_accuracy: 0.5714\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 26s 4s/step - loss: 0.6598 - accuracy: 0.6331 - val_loss: 0.6876 - val_accuracy: 0.5714\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 25s 4s/step - loss: 0.6571 - accuracy: 0.6331 - val_loss: 0.6848 - val_accuracy: 0.5714\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 27s 5s/step - loss: 0.6548 - accuracy: 0.6331 - val_loss: 0.6956 - val_accuracy: 0.5714\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 19s 3s/step - loss: 0.6578 - accuracy: 0.6331 - val_loss: 0.6939 - val_accuracy: 0.5714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc5cacfa2e0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'],)\n",
    "model.fit(X_train,Y_train,epochs=10,validation_data=(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 663ms/step - loss: 0.6939 - accuracy: 0.5714\n",
      "0.6939208507537842 is the loss\n",
      "0.5714285969734192 is the accuracy\n"
     ]
    }
   ],
   "source": [
    "## Loss and Accuracy of the model\n",
    "loss,accuracy = model.evaluate(X_test,Y_test)\n",
    "\n",
    "print(str(loss) + ' is the loss')\n",
    "print(str(accuracy) + ' is the accuracy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MRI_image_class_V2.model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('MRI_image_class_V2.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
